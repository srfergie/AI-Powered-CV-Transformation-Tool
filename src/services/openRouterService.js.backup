const axios = require('axios');

// Define the expected JSON structure for the LLM output
const PREDEFINED_JSON_STRUCTURE = {
  personalDetails: {
    name: '',
    email: '',
    phone: '',
    linkedin: '',
    github: '',
    location: '',
    website: ''
  },
  summary: '',
  education: [
    {
      institution: '',
      degree: '',
      major: '',
      graduationDate: '',
      gpa: '',
      location: '',
      honors: '',
      relevantCoursework: []
    },
  ],
  workExperience: [
    {
      company: '',
      position: '',
      startDate: '',
      endDate: '',
      location: '',
      responsibilities: [],
      achievements: [],
      technologies: []
    },
  ],
  projects: [
    {
      name: '',
      description: '',
      technologies: [],
      link: '',
      duration: '',
      role: ''
    }
  ],
  skills: {
    technical: [],
    soft: [],
    languages: [],
    tools: [],
    frameworks: [],
    databases: []
  },
  certifications: [
    {
      name: '',
      issuingOrganization: '',
      dateObtained: '',
      expirationDate: '',
      credentialId: ''
    }
  ],
  awards: [
    {
      name: '',
      organization: '',
      date: '',
      description: ''
    }
  ],
  publications: [
    {
      title: '',
      publication: '',
      date: '',
      authors: []
    }
  ]
};

/**
 * Chunk large text into smaller pieces for processing
 * @param {string} text - Text to chunk
 * @param {number} maxTokens - Maximum tokens per chunk (approximate)
 * @returns {Array} - Array of text chunks
 */
function chunkText(text, maxTokens = 12000) {
  // Rough estimate: 1 token ‚âà 4 characters
  const maxChars = maxTokens * 4;

  if (text.length <= maxChars) {
    return [text];
  }

  const chunks = [];
  let currentPos = 0;

  while (currentPos < text.length) {
    let endPos = Math.min(currentPos + maxChars, text.length);

    // Try to break at a natural point (sentence or paragraph)
    if (endPos < text.length) {
      const lastPeriod = text.lastIndexOf('.', endPos);
      const lastNewline = text.lastIndexOf('\n', endPos);
      const breakPoint = Math.max(lastPeriod, lastNewline);

      if (breakPoint > currentPos + maxChars * 0.5) {
        endPos = breakPoint + 1;
      }
    }

    chunks.push(text.substring(currentPos, endPos));
    currentPos = endPos;
  }

  return chunks;
}

const SYSTEM_PROMPT = `You are a professional CV data extraction specialist. Your task is to extract ALL detailed information from CV/resume documents with complete accuracy and comprehensiveness.

CRITICAL INSTRUCTIONS:
1. EXTRACT ALL CONTENT - Do not summarize or condense any information
2. PRESERVE ALL DETAILS - Every sentence, achievement, responsibility must be captured
3. SEPARATE SECTIONS - Distinguish between "Technical advisory roles", "Other relevant experience", etc.
4. EXTRACT ALL PUBLICATIONS - Do not limit to a subset, extract every single publication listed
5. EXTRACT ALL EXPERIENCE - Every job, role, consultancy, advisory position, volunteer work
6. PRESERVE ORIGINAL WORDING - Keep the professional language and specific terminology

DATA EXTRACTION REQUIREMENTS:

**Profile/Summary**: Extract the COMPLETE profile section with ALL paragraphs. Do not condense or summarize - capture every detail about:
- Professional background and years of experience
- Specific expertise areas and specializations  
- Types of organizations worked with
- Methodologies and approaches used
- Guest lecturer positions and academic roles
- Volunteer activities and board positions
- All achievements and recognition mentioned

**Experience Sections**: Extract ALL work experiences from ALL sections including:
- "Technical advisory roles and consultancies" (extract EVERY entry with full details)
- "Other relevant experience" (extract EVERY entry with full details)  
- "Professional experience" 
- "Work history"
- "Career summary"
- Any other work-related sections

For EACH role extract:
- Complete job title and organization
- Full date ranges
- Detailed description of responsibilities
- All achievements and accomplishments mentioned
- **SUB-PROJECTS**: Extract any specific projects, initiatives, client work, or detailed project descriptions mentioned within each role
- **TECHNOLOGIES**: Any tools, methodologies, or technologies used
- **TEAM DETAILS**: Team size, budget, project value if mentioned
- All bullet points and details

**Publications**: Extract ALL publications mentioned - do not limit to a sample:
- Every journal article, book, chapter, report
- All authors in correct order
- Complete titles with proper formatting
- Full publication details and dates
- Conference presentations and papers

**Education**: Extract all qualifications with:
- Complete degree titles with any honors/distinctions
- Full institution names
- Graduation dates/years
- Dissertation/thesis titles if mentioned
- Any relevant coursework or achievements

Return data in this exact JSON structure:`;

const MAIN_PROMPT = `
You are extracting data from a CV/resume. Extract ALL information comprehensively and return it in the EXACT JSON structure specified below.

CRITICAL REQUIREMENTS:
- Extract EVERY detail, do not summarize or condense
- Use the EXACT field names specified in the JSON structure
- Ensure personalInfo is a nested object, not flat fields
- Extract ALL work experience entries with complete details
- Include ALL responsibilities and achievements as arrays
- Preserve all original text and professional terminology

Resume text:
{resumeText}

Return ONLY a valid JSON object with this EXACT structure:

{
  "personalInfo": {
    "name": "Extract full name exactly as written in the CV",
    "title": "Extract professional title or current position", 
    "email": "Extract email address",
    "phone": "Extract phone number with country code",
    "location": "Extract full address or location",
    "linkedin": "Extract LinkedIn URL if mentioned",
    "website": "Extract website URL if mentioned",
    "nationality": "Extract nationality if mentioned"
  },
  "summary": "Extract the COMPLETE professional summary/profile section with ALL paragraphs and details. Do not summarize - copy the full text",
  "workExperience": [
    {
      "position": "Extract job title exactly as written",
      "company": "Extract company/organization name exactly as written", 
      "location": "Extract work location if mentioned",
      "startDate": "Extract start date",
      "endDate": "Extract end date or Present",
      "description": "Extract the complete job description paragraph",
      "responsibilities": ["Extract each responsibility as a separate array item", "Include ALL bullet points and tasks mentioned"],
      "achievements": ["Extract each achievement as a separate array item", "Include ALL accomplishments mentioned"]
    }
  ],
  "education": [
    {
      "degree": "Extract degree title with any honors or distinctions",
      "institution": "Extract institution name exactly as written",
      "graduationDate": "Extract year or date",
      "distinction": "Extract any honors, awards, or distinctions",
      "thesis": "Extract thesis title if mentioned"
    }
  ],
  "publications": [
    {
      "title": "Extract publication title exactly as written",
      "authors": ["Extract all author names in order"],
      "date": "Extract publication year or date", 
      "publication": "Extract journal, conference, or venue name"
    }
  ],
  "languages": ["Extract all languages mentioned with proficiency levels"],
  "skills": {
    "technical": ["Extract all technical skills, tools, software mentioned"],
    "soft": ["Extract all soft skills, personal attributes mentioned"]
  },
  "certifications": [
    {
      "name": "Extract certification name",
      "issuingOrganization": "Extract issuing organization",
      "dateObtained": "Extract date obtained"
    }
  ],
  "projects": [
    {
      "name": "Extract project name",
      "description": "Extract complete project description",
      "technologies": ["Extract technologies used"],
      "duration": "Extract project duration if mentioned"
    }
  ]
}

EXTRACTION RULES:
1. If a section doesn't exist, include it as empty array [] or empty string ""
2. Extract information from ALL sections including "Technical advisory roles", "Other relevant experience", etc.
3. For work experience, extract EVERY role mentioned regardless of section name
4. Preserve original professional language and terminology
5. Do not skip or truncate any content
6. Return valid JSON only - no markdown, no comments, no extra text`;

/**
 * Process resume text with OpenRouter API
 * Handles large documents by chunking if necessary
 * @param {string} resumeText - Raw text from CV
 * @param {Function} progressCallback - Optional progress callback
 * @returns {Promise<Object>} - Structured CV data
 */
async function processResumeWithOpenRouter(resumeText, progressCallback = null) {
  console.log('üîÑ Starting OpenRouter processing...');
  console.log(`üìÑ Document size: ${resumeText.length} characters (‚âà${Math.round(resumeText.length / 4)} tokens)`);

  if (progressCallback) progressCallback(10); // Starting AI processing

  const apiKey = process.env.OPENROUTER_API_KEY;
  if (!apiKey) {
    console.error('‚ùå OpenRouter API key is not set');
    throw new Error('OpenRouter API key is missing. Please configure it in your environment variables.');
  }

  // Validate API key format
  if (!apiKey.startsWith('sk-or-v1-')) {
    console.error('‚ùå OpenRouter API key format appears incorrect');
    throw new Error('OpenRouter API key format appears incorrect. Should start with "sk-or-v1-"');
  }

  console.log('‚úÖ API key found and validated');
  if (progressCallback) progressCallback(20); // API key validated

  const openRouterEndpoint = 'https://openrouter.ai/api/v1/chat/completions';

  // Check if document is too large and needs chunking
  const estimatedTokens = resumeText.length / 4; // Rough estimate
  const maxInputTokens = 120000; // Conservative limit for GPT-4 Turbo (128K total - 4K output)

  if (estimatedTokens > maxInputTokens) {
    console.log(`‚ö†Ô∏è Large document detected (‚âà${Math.round(estimatedTokens)} tokens). Using chunking approach...`);
    return await processLargeDocument(resumeText, progressCallback);
  }

  // Enhanced prompt for comprehensive data extraction for IOD PARC template
  const prompt = MAIN_PROMPT.replace('{resumeText}', resumeText);

  const requestPayload = {
    model: 'openai/gpt-4-turbo',
    messages: [
      { role: 'system', content: SYSTEM_PROMPT },
      { role: 'user', content: prompt },
    ],
    temperature: 0.1,
    max_tokens: 4000, // Increased for comprehensive extraction with larger model
  };

  console.log('üîÑ Making request to OpenRouter...');
  if (progressCallback) progressCallback(30); // Request being sent

  try {
    const response = await axios.post(
      openRouterEndpoint,
      requestPayload,
      {
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json',
          'HTTP-Referer': 'http://localhost:3000',
          'X-Title': 'Resume Transformer Tool',
        },
        timeout: 60000, // Increased timeout for GPT-4 Turbo processing
        onUploadProgress: (progressEvent) => {
          // Report upload progress to OpenRouter
          if (progressCallback) {
            const uploadProgress = Math.round((progressEvent.loaded * 30) / progressEvent.total);
            progressCallback(30 + uploadProgress); // 30-60% for upload
          }
        },
        onDownloadProgress: (progressEvent) => {
          // Report download progress from OpenRouter
          if (progressCallback && progressEvent.total) {
            const downloadProgress = Math.round((progressEvent.loaded * 30) / progressEvent.total);
            progressCallback(60 + downloadProgress); // 60-90% for download
          }
        }
      }
    );

    console.log('‚úÖ OpenRouter API response received');
    if (progressCallback) progressCallback(90); // Response received

    if (response.data && response.data.choices && response.data.choices.length > 0) {
      const messageContent = response.data.choices[0].message?.content;
      if (!messageContent) {
        throw new Error('OpenRouter API response did not contain message content.');
      }

      console.log('üìÑ Raw AI response:', messageContent.substring(0, 200) + '...');

      // Clean the response to extract JSON
      let jsonString = messageContent.trim();

      // Remove markdown code blocks if present
      const jsonMatch = jsonString.match(/```(?:json)?\s*([\s\S]*?)\s*```/);
      if (jsonMatch && jsonMatch[1]) {
        jsonString = jsonMatch[1].trim();
      }

      // Ensure it looks like JSON
      if (!jsonString.startsWith('{')) {
        const startIndex = jsonString.indexOf('{');
        if (startIndex !== -1) {
          jsonString = jsonString.substring(startIndex);
        }
      }

      if (!jsonString.endsWith('}')) {
        const endIndex = jsonString.lastIndexOf('}');
        if (endIndex !== -1) {
          jsonString = jsonString.substring(0, endIndex + 1);
        }
      }

      console.log('üîß Cleaned JSON string:', jsonString.substring(0, 100) + '...');
      if (progressCallback) progressCallback(95); // JSON cleaning complete

      try {
        const parsedJson = JSON.parse(jsonString);
        console.log('‚úÖ Successfully parsed JSON response');
        console.log('üìä Extracted sections:', Object.keys(parsedJson));

        // Validate that we have the expected structure
        if (!parsedJson.personalInfo && !parsedJson.personalDetails) {
          console.log('‚ö†Ô∏è Missing personalInfo, checking for flat structure...');
          // Check if AI returned flat structure and fix it
          if (parsedJson.name) {
            parsedJson.personalInfo = {
              name: parsedJson.name,
              title: parsedJson.title || '',
              email: parsedJson.email || '',
              phone: parsedJson.phone || '',
              location: parsedJson.location || '',
              nationality: parsedJson.nationality || ''
            };
            // Remove flat fields to avoid confusion
            delete parsedJson.name;
            delete parsedJson.title;
            delete parsedJson.email;
            delete parsedJson.phone;
            delete parsedJson.location;
            delete parsedJson.nationality;
          }
        }

        // Ensure workExperience exists (fix if AI returned 'experience' instead)
        if (!parsedJson.workExperience && parsedJson.experience) {
          parsedJson.workExperience = parsedJson.experience;
          delete parsedJson.experience;
        }

        console.log('üìã Final data structure validation:');
        console.log('‚Ä¢ Name:', parsedJson.personalInfo?.name || 'Missing');
        console.log('‚Ä¢ Summary length:', parsedJson.summary?.length || 0);
        console.log('‚Ä¢ Work experience count:', parsedJson.workExperience?.length || 0);

        if (progressCallback) progressCallback(100); // Parsing complete
        return parsedJson;
      } catch (parseError) {
        console.error('‚ùå Failed to parse JSON response:', parseError.message);
        console.error('üìÑ Raw response that failed:', jsonString);

        // Enhanced fallback: try to extract basic info from the text
        const nameMatch = jsonString.match(/"name":\s*"([^"]+)"/);
        const summaryMatch = jsonString.match(/"summary":\s*"([^"]+)"/);

        return {
          personalInfo: {
            name: nameMatch ? nameMatch[1] : 'Name not extracted',
            title: 'Professional',
            email: '',
            phone: '',
            location: '',
            nationality: ''
          },
          summary: summaryMatch ? summaryMatch[1] : resumeText.substring(0, 500) + '...',
          workExperience: [],
          education: [],
          publications: [],
          languages: [],
          skills: {
            technical: [],
            soft: []
          },
          certifications: [],
          projects: []
        };
      }
    } else {
      console.error('‚ùå Invalid response structure from OpenRouter');
      throw new Error('Invalid or empty response from OpenRouter API.');
    }
  } catch (error) {
    console.error('‚ùå OpenRouter API Error:', error.message);

    if (error.response) {
      console.error('API Error Status:', error.response.status);
      console.error('API Error Data:', error.response.data);
      throw new Error(`OpenRouter API request failed with status ${error.response.status}: ${JSON.stringify(error.response.data)}`);
    } else if (error.request) {
      console.error('No response received from OpenRouter API');
      throw new Error('No response received from OpenRouter API. Check network connectivity.');
    } else {
      console.error('Error setting up request:', error.message);
      throw new Error(`Error setting up OpenRouter API request: ${error.message}`);
    }
  }
}

/**
 * Process large documents by chunking and merging results
 * @param {string} resumeText - Large document text
 * @param {Function} progressCallback - Progress callback
 * @returns {Promise<Object>} - Merged structured data
 */
async function processLargeDocument(resumeText, progressCallback = null) {
  console.log('üìÑ Processing large document with chunking...');

  const chunks = chunkText(resumeText, 12000); // Conservative chunk size
  console.log(`üìë Document split into ${chunks.length} chunks`);

  const results = [];

  for (let i = 0; i < chunks.length; i++) {
    console.log(`üîÑ Processing chunk ${i + 1}/${chunks.length}...`);

    if (progressCallback) {
      const chunkProgress = 20 + (i / chunks.length) * 70; // 20-90% for chunk processing
      progressCallback(Math.round(chunkProgress));
    }

    try {
      // Process individual chunk with simplified prompt
      const chunkResult = await processChunk(chunks[i], i + 1, chunks.length);
      results.push(chunkResult);
    } catch (error) {
      console.error(`‚ùå Error processing chunk ${i + 1}:`, error.message);
      // Continue with other chunks
    }
  }

  console.log('üîÑ Merging chunk results...');
  if (progressCallback) progressCallback(95);

  // Merge all chunk results
  const mergedResult = mergeChunkResults(results);

  if (progressCallback) progressCallback(100);
  return mergedResult;
}

/**
 * Process a single chunk of text
 * @param {string} chunkText - Text chunk to process
 * @param {number} chunkIndex - Current chunk number
 * @param {number} totalChunks - Total number of chunks
 * @returns {Promise<Object>} - Structured data from chunk
 */
async function processChunk(chunkText, chunkIndex, totalChunks) {
  const apiKey = process.env.OPENROUTER_API_KEY;

  // Simplified prompt for chunk processing
  const prompt = `Extract CV information from this text chunk (${chunkIndex}/${totalChunks}) and return ONLY a valid JSON object with any available information:

{
  "personalInfo": {
    "name": "",
    "title": "",
    "email": "",
    "phone": "",
    "location": "",
    "nationality": ""
  },
  "workExperience": [],
  "education": [],
  "languages": [],
  "publications": [],
  "summary": ""
}

Extract only what's available in this chunk. Leave empty arrays/strings for missing data.

Text chunk:
${chunkText}`;

  const requestPayload = {
    model: 'openai/gpt-4-turbo',
    messages: [{ role: 'user', content: prompt }],
    temperature: 0.1,
    max_tokens: 2000
  };

  const response = await axios.post(
    'https://openrouter.ai/api/v1/chat/completions',
    requestPayload,
    {
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
        'HTTP-Referer': 'http://localhost:3000',
        'X-Title': 'Resume Transformer Tool - Chunk Processing',
      },
      timeout: 30000
    }
  );

  const messageContent = response.data.choices[0].message?.content;
  let jsonString = messageContent.trim();

  // Clean JSON response
  const jsonMatch = jsonString.match(/```(?:json)?\s*([\s\S]*?)\s*```/);
  if (jsonMatch && jsonMatch[1]) {
    jsonString = jsonMatch[1].trim();
  }

  return JSON.parse(jsonString);
}

/**
 * Merge results from multiple chunks
 * @param {Array} results - Array of chunk results
 * @returns {Object} - Merged structured data
 */
function mergeChunkResults(results) {
  const merged = {
    personalInfo: {},
    summary: '',
    workExperience: [],
    education: [],
    languages: [],
    publications: [],
    skills: { technical: [], soft: [], languages: [], tools: [], frameworks: [], databases: [] },
    certifications: [],
    awards: [],
    projects: [],
    countryExperience: ''
  };

  results.forEach(result => {
    if (!result) return;

    // Merge personal info (first non-empty values win)
    if (result.personalInfo) {
      Object.keys(result.personalInfo).forEach(key => {
        if (result.personalInfo[key] && !merged.personalInfo[key]) {
          merged.personalInfo[key] = result.personalInfo[key];
        }
      });
    }

    // Combine arrays
    if (result.workExperience) merged.workExperience.push(...result.workExperience);
    if (result.education) merged.education.push(...result.education);
    if (result.publications) merged.publications.push(...result.publications);
    if (result.languages) merged.languages.push(...result.languages);

    // Use longest summary
    if (result.summary && result.summary.length > merged.summary.length) {
      merged.summary = result.summary;
    }
  });

  // Remove duplicates from arrays
  merged.languages = [...new Set(merged.languages)];

  console.log(`‚úÖ Merged results from ${results.length} chunks`);
  return merged;
}

module.exports = {
  processResumeWithOpenRouter,
  PREDEFINED_JSON_STRUCTURE,
  chunkText,
  processLargeDocument
};

// Optional: Simple test call (comment out or remove before finalizing)
/*
if (require.main === module) {
  (async () => {
    // Mock resume text for testing
    const sampleResumeText = `
      John Doe
      john.doe@email.com | (123) 456-7890 | linkedin.com/in/johndoe | github.com/johndoe

      Summary:
      Highly motivated software engineer with 5 years of experience in full-stack development.

      Education:
      B.S. in Computer Science, University of Example, Graduated: May 2019, GPA: 3.8
      Major: Computer Science

      Work Experience:
      Tech Solutions Inc. - Software Engineer
      June 2019 - Present | Anytown, USA
      - Developed and maintained web applications using React, Node.js, and PostgreSQL.
      - Collaborated with cross-functional teams to deliver high-quality software.

      Old Company - Junior Developer
      Jan 2018 - May 2019 | Anytown, USA
      - Assisted senior developers in coding and testing.

      Projects:
      Personal Portfolio Website - A responsive website showcasing my projects. (Technologies: HTML, CSS, JavaScript)

      Skills:
      Technical: JavaScript, React, Node.js, Python, SQL, Git, Docker
      Soft Skills: Communication, Teamwork, Problem-solving
      Languages: English (Native), Spanish (Conversational)

      Certifications:
      Certified Kubernetes Application Developer - CNCF, 2021
    `;

    // IMPORTANT: Set your OPENROUTER_API_KEY environment variable before running this test.
    // e.g., export OPENROUTER_API_KEY='your_actual_api_key'
    if (!process.env.OPENROUTER_API_KEY) {
      console.error("Please set the OPENROUTER_API_KEY environment variable to test.");
      console.log("Skipping OpenRouter service test.");
      return;
    }
    
    console.log("Attempting to process sample resume with OpenRouter...");
    try {
      const structuredData = await processResumeWithOpenRouter(sampleResumeText);
      console.log('Structured Resume Data:', JSON.stringify(structuredData, null, 2));
    } catch (error) {
      console.error('Error during OpenRouter service test:', error.message);
    }
  })();
}
*/
